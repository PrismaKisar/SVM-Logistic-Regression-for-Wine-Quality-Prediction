{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd4828a0",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf18d0fb",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This document presents the data preprocessing procedures designed to optimize model performance and maximize predictive capability. The analysis begins with the requisite library imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc8a1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd()\n",
    "while not (project_root / \"src\").exists():\n",
    "    project_root = project_root.parent\n",
    "\n",
    "sys.path.append(str(project_root / \"src\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62084ad",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a6a25b",
   "metadata": {},
   "source": [
    "Initially, non-numeric columns such as wine type must be encoded appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dd4329",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_wine = pd.read_csv('../data/raw/winequality-red.csv', sep=';')\n",
    "white_wine = pd.read_csv('../data/raw/winequality-white.csv', sep=';')\n",
    "\n",
    "red_wine['wine_type'] = 'red'\n",
    "white_wine['wine_type'] = 'white'\n",
    "wine_data = pd.concat([red_wine, white_wine], axis=0, ignore_index=True)\n",
    "wine_data = pd.get_dummies(wine_data, columns=['wine_type'], dtype=int)\n",
    "\n",
    "X = wine_data.drop(columns='quality')\n",
    "y = wine_data['quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25830c27",
   "metadata": {},
   "source": [
    "## Data Splitting\n",
    "The data must then be partitioned into training and testing sets to prevent issues such as data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ca5ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(X, y, test_size=0.2, random_state=None, stratify=None):\n",
    "\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    n_samples = len(X)\n",
    "    n_test = int(n_samples * test_size)\n",
    "\n",
    "    if stratify is not None:\n",
    "        indices_train = []\n",
    "        indices_test = []\n",
    "        \n",
    "        for class_val in np.unique(stratify):\n",
    "            class_indices = np.where(stratify == class_val)[0]\n",
    "            n_class_test = int(len(class_indices) * test_size)\n",
    "            \n",
    "            np.random.shuffle(class_indices)\n",
    "            \n",
    "            indices_test.extend(class_indices[:n_class_test])\n",
    "            indices_train.extend(class_indices[n_class_test:])\n",
    "        \n",
    "        train_idx = np.array(indices_train)\n",
    "        test_idx = np.array(indices_test)\n",
    "\n",
    "    else:\n",
    "        indices = np.arange(n_samples)\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "        test_idx = indices[:n_test]\n",
    "        train_idx = indices[n_test:]\n",
    "\n",
    "    return X.iloc[train_idx].copy(), X.iloc[test_idx].copy(), y.iloc[train_idx].copy(), y.iloc[test_idx].copy()\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_train_test(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ccb0d1",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "Based on the correlations identified during exploratory analysis, four features will be addressed: *free sulfur dioxide*, *total sulfur dioxide*, *density*, and *alcohol*. The first pair exhibits a correlation of 0.72, and a potentially effective solution involves creating a unified feature by calculating the ratio of free sulfur dioxide to total sulfur dioxide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8316f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['free sulfur dioxide ratio'] = X_train['free sulfur dioxide'] / X_train['total sulfur dioxide']\n",
    "X_train = X_train.drop(columns=['total sulfur dioxide', 'free sulfur dioxide'])\n",
    "\n",
    "X_test['free sulfur dioxide ratio'] = X_test['free sulfur dioxide'] / X_test['total sulfur dioxide']\n",
    "X_test = X_test.drop(columns=['total sulfur dioxide', 'free sulfur dioxide'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27da3ccc",
   "metadata": {},
   "source": [
    "For the second pair, the feature with lower correlation to the target variable (*density*) will be removed from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0569b21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Alcohol Correlation: {wine_data['quality'].corr(wine_data['alcohol'])}')\n",
    "print(f'Density Correlation: {wine_data['quality'].corr(wine_data['density'])}')\n",
    "\n",
    "X_train = X_train.drop(columns='density')\n",
    "X_test = X_test.drop(columns='density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fe2987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "CORRELATION_THRESHOLD = 0.35\n",
    "\n",
    "correlation_matrix = X_train.corr(numeric_only=True)\n",
    "\n",
    "triangle_mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "weak_corr_mask = abs(correlation_matrix) < CORRELATION_THRESHOLD\n",
    "combined_mask = triangle_mask | weak_corr_mask\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(correlation_matrix,\n",
    "            mask=combined_mask,\n",
    "            annot=True,\n",
    "            cmap='coolwarm',\n",
    "            center=0)\n",
    "\n",
    "plt.title(f'Strong Correlations (>{CORRELATION_THRESHOLD})')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717ba407",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2cd316",
   "metadata": {},
   "source": [
    "To facilitate model optimization, the data will be standardized using standard scaling techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7deb4764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import StandardScaler\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "X_train = standard_scaler.fit_transform(X_train)\n",
    "X_test = standard_scaler.transform(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
