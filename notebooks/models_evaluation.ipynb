{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbf384cf",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this notebook, optimal hyperparameters will be selected and the performance of both models will be evaluated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd80834",
   "metadata": {},
   "source": [
    "### Imports\n",
    "The analysis commences with the necessary imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dbccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd()\n",
    "while not (project_root / \"src\").exists():\n",
    "    project_root = project_root.parent\n",
    "\n",
    "sys.path.append(str(project_root / \"src\"))\n",
    "\n",
    "from model_selection import grid_search_cv\n",
    "from models import SVM, LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebe8b37",
   "metadata": {},
   "source": [
    "### Notebook Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d829b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = 'f1'\n",
    "RUNMODE = 'evaluation' # with 'training' value computational expensive will be enabled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8d7df4",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "The data will be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac528db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.read_csv('../data/processed/X_train.csv')\n",
    "y_train_df = pd.read_csv('../data/processed/y_train.csv')\n",
    "X_test_df = pd.read_csv('../data/processed/X_test.csv')\n",
    "y_test_df = pd.read_csv('../data/processed/y_test.csv')\n",
    "\n",
    "y_train = np.where(y_train_df['quality'] >= 6, 1, -1)\n",
    "y_test = np.where(y_test_df['quality'] >= 6, 1, -1)\n",
    "\n",
    "X_train = X_train_df.to_numpy()\n",
    "X_test = X_test_df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb260a86",
   "metadata": {},
   "source": [
    "# Models Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c97e23",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "To identify optimal hyperparameters, multiple rounds of grid search are required to thoroughly explore all possible parameter combinations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9635426a",
   "metadata": {},
   "source": [
    "### SVM\n",
    "For SVMs, two primary parameters require optimization: the number of iterations (*n_iters*) and the regularization parameter lambda (*lambda_param*). Typically, the number of folds ranges between 5 to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d7e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_param_grid = {\n",
    "        'n_iters': [1000, 2000, 3000, 4000, 5000, 6000, 7000],\n",
    "        'lambda_param' : [1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "    }\n",
    "\n",
    "svm_best_params, svm_best_metrics = grid_search_cv(SVM, svm_param_grid, X_train, y_train, cv=5, scoring=METRICS)\n",
    "print(f'SVM best parameter: {svm_best_params}')\n",
    "print(f'SVM best metrics: {svm_best_metrics}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c084452",
   "metadata": {},
   "source": [
    "The optimal hyperparameters identified are *n_iters: 2000* and *lambda_param: 0.01*. A refined search will now be conducted within the neighborhood of these parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665fd6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_param_grid = {\n",
    "        'n_iters': [1500, 1750, 2000, 2250, 2500],\n",
    "        'lambda_param' : [5e-1, 3e-1, 1e-1, 9e-2, 7e-2]\n",
    "    }\n",
    "\n",
    "svm_best_params, svm_best_metrics = grid_search_cv(SVM, svm_param_grid, X_train, y_train, cv=5, scoring=METRICS)\n",
    "print(f'SVM best parameter: {svm_best_params}')\n",
    "print(f'SVM best metrics: {svm_best_metrics}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa452b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_n_iters = svm_best_params['n_iters']\n",
    "svm_lambda_param = svm_best_params['lambda_param']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1bf5da",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "As with SVMs, the parameters include *n_iters* and *lambda_param*, however, this model additionally incorporates the learning rate parameter (*learning_rate*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60341c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUNMODE == 'training':\n",
    "    lr_param_grid = {\n",
    "            'n_iters': [1, 2, 5, 10, 20],\n",
    "            'lambda_param' : [1e-1, 1e-2, 1e-3],\n",
    "            'learning_rate' : [1e-1, 1e-2, 1e-3]\n",
    "        }\n",
    "\n",
    "    lr_best_params, lr_best_metrics = grid_search_cv(LogisticRegression, lr_param_grid, X_train, y_train, cv=5, scoring=METRICS)\n",
    "    print(f'Logistic Regression best parameter: {lr_best_params}')\n",
    "    print(f'Logistic Regression best metrics: {lr_best_metrics}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da87831",
   "metadata": {},
   "source": [
    "The best parameter are *n_iters: 5*, *lambda_param: 0.001* and *learning_rate: 0.01*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7299edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUNMODE == 'training':\n",
    "    lr_param_grid = {\n",
    "            'n_iters': [3, 4, 5, 6, 7],\n",
    "            'lambda_param' : [5e-3, 1e-3, 5e-4],\n",
    "            'learning_rate' : [5e-2, 1e-2, 5e-3]\n",
    "        }\n",
    "\n",
    "    lr_best_params, lr_best_metrics = grid_search_cv(LogisticRegression, lr_param_grid, X_train, y_train, cv=5, scoring=METRICS)\n",
    "    print(f'Logistic Regression best parameter: {lr_best_params}')\n",
    "    print(f'Logistic Regression best metrics: {lr_best_metrics}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481a30d6",
   "metadata": {},
   "source": [
    "It is notable that the model does not necessarily tend toward high iteration values, indicating that convergence likely occurs rapidly. This phenomenon will be more readily observable through the examination of learning curves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0bf996",
   "metadata": {},
   "source": [
    "Due to time constraints, the hyperparameters are manually assigned to variables; however, the grid search procedure remains fully reproducible. *(1m 31s and 54s)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77b38a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUNMODE == 'training':\n",
    "    lr_n_iters = lr_best_params['n_iters']\n",
    "    lr_lambda_param = lr_best_params['lambda_param']\n",
    "    lr_learning_rate = lr_best_params['learning_rate']\n",
    "else: \n",
    "    lr_n_iters = 5\n",
    "    lr_lambda_param = 5e-4\n",
    "    lr_learning_rate = 5e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a04598",
   "metadata": {},
   "source": [
    "## Learning Curves\n",
    "It is particularly valuable to analyze the learning curves of the various algorithms to observe how and when convergence occurs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bdba25",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be13d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f1(predictions, y_true):\n",
    "    tp = np.sum((predictions == 1) & (y_true == 1))\n",
    "    fp = np.sum((predictions == 1) & (y_true == -1))\n",
    "    fn = np.sum((predictions == -1) & (y_true == 1))\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    \n",
    "    return f1\n",
    "\n",
    "def plot_learning_curve(model_class, X_train, y_train, X_test, y_test, iterations_list, **model_kwargs):\n",
    "    \n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    \n",
    "    for n_iter in iterations_list:\n",
    "        model = model_class(n_iters=n_iter, **model_kwargs)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        train_pred = model.predict(X_train)\n",
    "        test_pred = model.predict(X_test)\n",
    "        \n",
    "        train_score = calculate_f1(train_pred, y_train)\n",
    "        test_score = calculate_f1(test_pred, y_test)\n",
    "        \n",
    "        train_scores.append(train_score)\n",
    "        test_scores.append(test_score)\n",
    "        \n",
    "        print(f\"Iter {n_iter}: Train={train_score:.3f}, Test={test_score:.3f}\")\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(iterations_list, train_scores, 'o-', label='Training', color='blue')\n",
    "    plt.plot(iterations_list, test_scores, 'o-', label='Test', color='red')\n",
    "    \n",
    "    plt.xlabel('Iteration Number')\n",
    "    plt.ylabel('F1-Score')\n",
    "    plt.title('Learning Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964f2023",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5f0c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(SVM, X_train, y_train, X_test, y_test, [100, 300, 500, 1000, 1500, 2000, 3000, 4000, 5000, 6000, 7000], lambda_param=svm_lambda_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80621632",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d615089",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(LogisticRegression, X_train, y_train, X_test, y_test, [0, 1, 3, 5, 7, 8, 9, 10, 15, 20], lambda_param=lr_lambda_param, learning_rate=lr_learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b32c089",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "Logistic Regression demonstrates superior efficiency and stability for this dataset, exhibiting rapid convergence and enhanced generalization capability. While SVM achieves acceptable performance, it requires extended training time and displays greater instability, likely attributable to the complexity of the margin optimization process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d9c14e",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bf0998",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7e192b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(predictions, y_test):\n",
    "    tp = np.sum((predictions == 1) & (y_test == 1))\n",
    "    fp = np.sum((predictions == 1) & (y_test == -1))\n",
    "    tn = np.sum((predictions == -1) & (y_test == -1))\n",
    "    fn = np.sum((predictions == -1) & (y_test == 1))\n",
    "    \n",
    "    accuracy = (tp + tn) / len(y_test)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'tp': tp, 'fp': fp, 'tn': tn, 'fn': fn\n",
    "    }\n",
    "\n",
    "def plot_metrics(predictions, y_test):\n",
    "    metrics = calculate_metrics(predictions, y_test)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    names = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
    "    values = [metrics['accuracy'], metrics['precision'], \n",
    "              metrics['recall'], metrics['f1']]\n",
    "    \n",
    "    ax1.bar(names, values, color=['skyblue', 'lightcoral', 'lightgreen', 'orange'])\n",
    "    ax1.set_ylim(0, 1)\n",
    "    ax1.set_title('Metrics')\n",
    "    \n",
    "    for i, v in enumerate(values):\n",
    "        ax1.text(i, v + 0.02, f'{v:.3f}', ha='center')\n",
    "    \n",
    "    cm = [[metrics['tn'], metrics['fp']], \n",
    "          [metrics['fn'], metrics['tp']]]\n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax2,\n",
    "                xticklabels=['Bad', 'Good'], yticklabels=['Bad', 'Good'])\n",
    "    ax2.set_title('Confusion Matrix')\n",
    "    ax2.set_xlabel('Predicted')\n",
    "    ax2.set_ylabel('Actual')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6a7a52",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b567659",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVM(svm_n_iters, svm_lambda_param)\n",
    "svm.fit(X_train, y_train)\n",
    "predictions = svm.predict(X_test)\n",
    "plot_metrics(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973b2a4e",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89dc801",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(lr_n_iters, lr_lambda_param, lr_learning_rate)\n",
    "lr.fit(X_train, y_train)\n",
    "predictions = lr.predict(X_test)\n",
    "plot_metrics(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13dd607",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "Performance visualization indicates that logistic regression generally demonstrates superior performance on this specific dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d648ed3",
   "metadata": {},
   "source": [
    "# Models with Kernel Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e1a829",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45af1341",
   "metadata": {},
   "source": [
    "### SVM\n",
    "Non-linear kernel models will now be tuned, specifically employing polynomial kernels in this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627cf532",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUNMODE == 'training':\n",
    "    svm_k_param_grid = {\n",
    "            'kernel': ['poly'],\n",
    "            'n_iters': [3000, 4000, 5000],\n",
    "            'lambda_param': [1, 1e-1, 1e-2],\n",
    "            'degree': [2, 3]\n",
    "        }\n",
    "\n",
    "    svm_k_best_params, svm_k_best_metrics = grid_search_cv(SVM, svm_k_param_grid, X_train, y_train, cv=5, scoring=METRICS)\n",
    "    print(f'SVM best parameter: {svm_k_best_params}')\n",
    "    print(f'SVM best metrics: {svm_k_best_metrics}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dca9077",
   "metadata": {},
   "source": [
    "Due to time constraints, the hyperparameters are manually assigned to variables; however, the grid search procedure remains fully reproducible. *(13 min 20s)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3058df",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUNMODE == 'training':\n",
    "    svm_k_n_iters = svm_k_best_params['n_iters']\n",
    "    svm_k_lambda_param = svm_k_best_params['lambda_param']\n",
    "    svm_k_degree = svm_k_best_params['degree']\n",
    "else:\n",
    "    svm_k_n_iters = 4000\n",
    "    svm_k_lambda_param = 1\n",
    "    svm_k_degree = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2141ab",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038bc55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUNMODE == 'training':\n",
    "    lr_k_param_grid = {\n",
    "            'kernel': ['poly'],\n",
    "            'n_iters': [2, 5, 10, 20, 50, 100],\n",
    "            'lambda_param': [1e-4, 1e-5],\n",
    "            'learning_rate': [1e-4, 1e-5],\n",
    "            'degree': [2, 3]\n",
    "        }\n",
    "\n",
    "    lr_k_best_params, lr_k_best_metrics = grid_search_cv(LogisticRegression, lr_k_param_grid, X_train, y_train, cv=5, scoring=METRICS)\n",
    "    print(f'SVM best parameter: {lr_k_best_params}')\n",
    "    print(f'SVM best metrics: {lr_k_best_metrics}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e7f39b",
   "metadata": {},
   "source": [
    "Due to time constraints, the hyperparameters are manually assigned to variables; however, the grid search procedure remains fully reproducible. *(14 min 57s)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83527506",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUNMODE == 'training':\n",
    "    lr_k_n_iters = lr_k_best_params['n_iters']\n",
    "    lr_k_lambda_param = lr_k_best_params['lambda_param']\n",
    "    lr_k_learning_rate = lr_k_best_params['learning_rate']\n",
    "    lr_k_degree = lr_k_best_params['degree']\n",
    "\n",
    "else: \n",
    "    lr_k_n_iters = 50\n",
    "    lr_k_lambda_param = 1e-4\n",
    "    lr_k_learning_rate = 1e-5\n",
    "    lr_k_degree = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3704f08",
   "metadata": {},
   "source": [
    "With the parameters obtained, the learning curves will now be visualized to analyze convergence behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0879aa",
   "metadata": {},
   "source": [
    "## Learning Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b693706",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0f9534",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(SVM, X_train, y_train, X_test, y_test, [100, 300, 500, 1000, 1500, 2000, 3000, 4000, 5000, 6000, 7000], lambda_param=svm_k_lambda_param, kernel='poly', degree=svm_k_degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26192271",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bab5da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(LogisticRegression, X_train, y_train, X_test, y_test, [0, 1, 3, 5, 7, 8, 9, 10, 15, 20], lambda_param=lr_k_lambda_param, learning_rate=lr_k_learning_rate, kernel='poly', degree=lr_k_degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc53324",
   "metadata": {},
   "source": [
    "It is evident that SVM requires significantly more iterations than logistic regression, which is expected given that logistic regression updates parameters for each example at every iteration. Additionally, SVM performance has improved, while logistic regression exhibits slight overfitting tendencies as iterations progress."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3811617",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bc56a1",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11714a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVM(n_iters=svm_k_n_iters, lambda_param=svm_k_lambda_param, kernel='poly', degree=svm_k_degree)\n",
    "svm.fit(X_train, y_train)\n",
    "predictions = svm.predict(X_test)\n",
    "plot_metrics(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01d1fb2",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b7d910",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(n_iters=lr_k_n_iters, lambda_param=lr_k_lambda_param, learning_rate=lr_k_learning_rate, kernel='poly', degree=lr_k_degree)\n",
    "lr.fit(X_train, y_train)\n",
    "predictions = lr.predict(X_test)\n",
    "plot_metrics(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386ba630",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "With kernel methods, SVM performance has significantly improved, although logistic regression continues to demonstrate superior results. It is also notable that recall metrics are consistently higher than precision across both models. Regarding accuracy, performance approximates 75%, which represents a satisfactory result considering the baseline probability established by the dataset imbalance (60-40)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
