{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb260a86",
   "metadata": {},
   "source": [
    "# Models Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf384cf",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this notebook, optimal hyperparameters will be selected and the performance of both models will be evaluated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd80834",
   "metadata": {},
   "source": [
    "### Imports\n",
    "The analysis commences with the necessary imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dbccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd()\n",
    "while not (project_root / \"src\").exists():\n",
    "    project_root = project_root.parent\n",
    "\n",
    "sys.path.append(str(project_root / \"src\"))\n",
    "\n",
    "from model_selection import grid_search_cv\n",
    "from models import SVM, LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8d7df4",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "The data will be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac528db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.read_csv('../data/processed/X_train.csv')\n",
    "y_train_df = pd.read_csv('../data/processed/y_train.csv')\n",
    "X_test_df = pd.read_csv('../data/processed/X_test.csv')\n",
    "y_test_df = pd.read_csv('../data/processed/y_test.csv')\n",
    "\n",
    "y_train = np.where(y_train_df['quality'] >= 6, 1, -1)\n",
    "y_test = np.where(y_test_df['quality'] >= 6, 1, -1)\n",
    "\n",
    "X_train = X_train_df.to_numpy()\n",
    "X_test = X_test_df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c97e23",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "To identify optimal hyperparameters, multiple rounds of grid search are required to thoroughly explore all possible parameter combinations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9635426a",
   "metadata": {},
   "source": [
    "### SVM\n",
    "For SVMs, two primary parameters require optimization: the number of iterations (*n_iters*) and the regularization parameter lambda (*lambda_param*). Typically, the number of folds ranges between 5 to 10; however, given our computational capacity, we can extend this to 100 folds without exceeding three minutes of processing time, thereby approximating Leave-One-Out validation and achieving a more robust validation framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d7e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_param_grid = {\n",
    "        'n_iters': [1000, 2000, 3000, 4000, 5000, 6000],\n",
    "        'lambda_param' : [1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n",
    "    }\n",
    "\n",
    "svm_best_params, svm_best_metrics = grid_search_cv(SVM, svm_param_grid, X_train, y_train, 100)\n",
    "print(f'SVM best parameter: {svm_best_params}')\n",
    "print(f'SVM best metrics: {svm_best_metrics}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c084452",
   "metadata": {},
   "source": [
    "The optimal hyperparameters identified are *n_iters: 5000* and *lambda_param: 0.1*. A refined search will now be conducted within the neighborhood of these parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665fd6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_param_grid = {\n",
    "        'n_iters': [4500, 4750, 5000, 5250, 5500],\n",
    "        'lambda_param' : [5e-1, 3e-1, 1e-1, 9e-2, 7e-2]\n",
    "    }\n",
    "\n",
    "svm_best_params, svm_best_metrics = grid_search_cv(SVM, svm_param_grid, X_train, y_train, 100)\n",
    "print(f'SVM best parameter: {svm_best_params}')\n",
    "print(f'SVM best metrics: {svm_best_metrics}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc7d65e",
   "metadata": {},
   "source": [
    "Due to time constraints, the hyperparameters are manually assigned to variables; however, the grid search procedure remains fully reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac16b230",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_n_iters = 5000\n",
    "svm_lambda_param = 1e-7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1bf5da",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "As with SVMs, the parameters include n_iters and lambda_param, however, this model additionally incorporates the learning rate parameter (*learning_rate*). Unlike SVMs, this implementation exhibits significantly lower computational efficiency, necessitating the use of a more modest number of folds and a more judicious hyperparameter search approach rather than brute force methods. The initial step involves establishing the appropriate orders of magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60341c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_param_grid = {\n",
    "        'n_iters': [10, 100, 300],\n",
    "        'lambda_param' : [1e-1, 1e-3],\n",
    "        'learning_rate' : [1e-1, 1e-3]\n",
    "    }\n",
    "\n",
    "lr_best_params, lr_best_metrics = grid_search_cv(LogisticRegression, lr_param_grid, X_train, y_train, 5)\n",
    "print(f'Logistic Regression best parameter: {lr_best_params}')\n",
    "print(f'Logistic Regression best metrics: {lr_best_metrics}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da87831",
   "metadata": {},
   "source": [
    "It is immediately apparent that convergence occurs toward very low values of lambda and learning rate, while the number of iterations settles on an intermediate value. Given the probable noise introduced by the reduced number of folds, a cautious approach is required to explore the parameter neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7299edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_param_grid = {\n",
    "        'n_iters': [50, 150],\n",
    "        'lambda_param' : [1e-2, 1e-4],\n",
    "        'learning_rate' : [1e-2, 1e-4]\n",
    "    }\n",
    "\n",
    "lr_best_params, lr_best_metrics = grid_search_cv(LogisticRegression, lr_param_grid, X_train, y_train, 5)\n",
    "print(f'Logistic Regression best parameter: {lr_best_params}')\n",
    "print(f'Logistic Regression best metrics: {lr_best_metrics}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481a30d6",
   "metadata": {},
   "source": [
    "It is notable that the model does not necessarily tend toward high iteration values, indicating that convergence likely occurs rapidly. This phenomenon will be more readily observable through the examination of learning curves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178739aa",
   "metadata": {},
   "source": [
    "Utilizing the optimal parameters from previous trials, the number of folds will be doubled to reduce noise and identify robust hyperparameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b931e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_param_grid = {\n",
    "        'n_iters': [50, 100],\n",
    "        'lambda_param' : [1e-3, 1e-4],\n",
    "        'learning_rate' : [1e-2, 1e-3]\n",
    "    }\n",
    "\n",
    "lr_best_params, lr_best_metrics = grid_search_cv(LogisticRegression, lr_param_grid, X_train, y_train, 10)\n",
    "print(f'Logistic Regression best parameter: {lr_best_params}')\n",
    "print(f'Logistic Regression best metrics: {lr_best_metrics}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e235fde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_param_grid = {\n",
    "        'n_iters': [50, 100],\n",
    "        'lambda_param' : [1e-4, 1e-5, 1e-6],\n",
    "        'learning_rate' : [1e-3]\n",
    "    }\n",
    "\n",
    "lr_best_params, lr_best_metrics = grid_search_cv(LogisticRegression, lr_param_grid, X_train, y_train, 10)\n",
    "print(f'Logistic Regression best parameter: {lr_best_params}')\n",
    "print(f'Logistic Regression best metrics: {lr_best_metrics}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0bf996",
   "metadata": {},
   "source": [
    "Due to time constraints, the hyperparameters are manually assigned to variables; however, the grid search procedure remains fully reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77b38a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_n_iters = 50\n",
    "lr_lambda_param = 1e-5\n",
    "lr_learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a04598",
   "metadata": {},
   "source": [
    "## Learning Curves\n",
    "It is particularly valuable to analyze the learning curves of the various algorithms to observe how and when convergence occurs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bdba25",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be13d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f1(predictions, y_true):\n",
    "    tp = np.sum((predictions == 1) & (y_true == 1))\n",
    "    fp = np.sum((predictions == 1) & (y_true == -1))\n",
    "    fn = np.sum((predictions == -1) & (y_true == 1))\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    \n",
    "    return f1\n",
    "\n",
    "def plot_learning_curve(model_class, X_train, y_train, X_test, y_test, iterations_list, **model_kwargs):\n",
    "    \n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    \n",
    "    for n_iter in iterations_list:\n",
    "        model = model_class(n_iters=n_iter, **model_kwargs)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        train_pred = model.predict(X_train)\n",
    "        test_pred = model.predict(X_test)\n",
    "        \n",
    "        train_score = calculate_f1(train_pred, y_train)\n",
    "        test_score = calculate_f1(test_pred, y_test)\n",
    "        \n",
    "        train_scores.append(train_score)\n",
    "        test_scores.append(test_score)\n",
    "        \n",
    "        print(f\"Iter {n_iter}: Train={train_score:.3f}, Test={test_score:.3f}\")\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(iterations_list, train_scores, 'o-', label='Training', color='blue')\n",
    "    plt.plot(iterations_list, test_scores, 'o-', label='Test', color='red')\n",
    "    \n",
    "    plt.xlabel('Iteration Number')\n",
    "    plt.ylabel('F1-Score')\n",
    "    plt.title('Learning Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964f2023",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5f0c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(SVM, X_train, y_train, X_test, y_test, [100, 300, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500, 6000, 6500, 7000], lambda_param=svm_lambda_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80621632",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d615089",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(LogisticRegression, X_train, y_train, X_test, y_test, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 50], lambda_param=lr_lambda_param, learning_rate=lr_learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b32c089",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "Analysis of these two graphs reveals highly interesting differences in model behavior. The first graph displays rather chaotic patterns, with performance metrics oscillating continuously without achieving stability. The model appears unable to converge on an optimal solution, continuously altering its trajectory with each iteration. This behavior suggests that the optimization algorithm encounters difficulty in identifying a coherent direction.\n",
    "\n",
    "The second graph presents a markedly different narrative. Here, the model initiates with modest performance but demonstrates rapid and systematic improvement during initial iterations, subsequently stabilizing at consistently high performance levels. This represents the classical convergence pattern expected from well-designed algorithms: rapid initial learning followed by stable retention of acquired knowledge.\n",
    "\n",
    "From a practical perspective, the second model would prove significantly more reliable for deployment. It not only achieves superior performance but does so in a predictable and stable manner. Conversely, while the first model occasionally reaches noteworthy peaks, its inherent instability renders it unsuitable for real-world applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d9c14e",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bf0998",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7e192b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(predictions, y_test):\n",
    "    tp = np.sum((predictions == 1) & (y_test == 1))\n",
    "    fp = np.sum((predictions == 1) & (y_test == -1))\n",
    "    tn = np.sum((predictions == -1) & (y_test == -1))\n",
    "    fn = np.sum((predictions == -1) & (y_test == 1))\n",
    "    \n",
    "    accuracy = (tp + tn) / len(y_test)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'tp': tp, 'fp': fp, 'tn': tn, 'fn': fn\n",
    "    }\n",
    "\n",
    "def plot_metrics(predictions, y_test):\n",
    "    metrics = calculate_metrics(predictions, y_test)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    names = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
    "    values = [metrics['accuracy'], metrics['precision'], \n",
    "              metrics['recall'], metrics['f1']]\n",
    "    \n",
    "    ax1.bar(names, values, color=['skyblue', 'lightcoral', 'lightgreen', 'orange'])\n",
    "    ax1.set_ylim(0, 1)\n",
    "    ax1.set_title('Metrics')\n",
    "    \n",
    "    for i, v in enumerate(values):\n",
    "        ax1.text(i, v + 0.02, f'{v:.3f}', ha='center')\n",
    "    \n",
    "    cm = [[metrics['tn'], metrics['fp']], \n",
    "          [metrics['fn'], metrics['tp']]]\n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax2,\n",
    "                xticklabels=['Bad', 'Good'], yticklabels=['Bad', 'Good'])\n",
    "    ax2.set_title('Confusion Matrix')\n",
    "    ax2.set_xlabel('Predicted')\n",
    "    ax2.set_ylabel('Actual')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6a7a52",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b567659",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVM(svm_n_iters, svm_lambda_param)\n",
    "svm.fit(X_train, y_train)\n",
    "predictions = svm.predict(X_test)\n",
    "plot_metrics(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973b2a4e",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89dc801",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(lr_n_iters, lr_lambda_param, lr_learning_rate)\n",
    "lr.fit(X_train, y_train)\n",
    "predictions = lr.predict(X_test)\n",
    "plot_metrics(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13dd607",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "Performance visualization indicates that logistic regression generally demonstrates superior performance on this specific dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
